{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf5da54",
   "metadata": {},
   "source": [
    "# Pytorch Geometric\n",
    "\n",
    "La paquetería de pytorch geometric está pensada para elaborar capas de redes gráficas. Esta paquetería ya contiene algunas capas pre-definidas, pero también nos permite elaborar nuestras propias capas para integrarlas en un modelo de red neuronal de gráfica. Pytorch geometric se suele utilizar junto con torch, pues dependen uno del otro.\n",
    "\n",
    "Importamos entonces torch, torch.nn, torch_geometric y torch_geometric.nn además de otras paqueterías auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f524bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as geo_torch\n",
    "import torch_geometric.nn as geo_nn\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0e456",
   "metadata": {},
   "source": [
    "## Creación de datos\n",
    "\n",
    "En primer lugar, definiremos nuestros datos. En este caso, podemos usar tensores en formato torch. Declararemos unos datos de entrada, unas clases de salida y una matriz de adyacencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94515334",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0], dtype=torch.long)\n",
    "A = torch.tensor([[0, 1, 0],[1, 0, 1],[0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c27ba",
   "metadata": {},
   "source": [
    "Pytorch geometric trabaj con un formato particular para indicar las aristas de la gráfica. Este formato está basado en dos renglones donde cada columna presenta una adyacencia. Por ejemplo, si tenemos una adyacencia $(n_i,n_j) \\in E$, entonces crearemos la columna:\n",
    "\n",
    "$$\\begin{bmatrix} n_i \\\\ n_j \\end{bmatrix}$$\n",
    "\n",
    "En el caso anterior, por ejemplo, tendríamos el siguiente ínidice de aristas:\n",
    "\n",
    "$$\\begin{bmatrix} n_0 & n_1 & n_1 & n_2 \\\\ n_1 & n_0 & n_2 & n_1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55301bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = A.nonzero().t().contiguous() \n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e7f5ac",
   "metadata": {},
   "source": [
    "Para generar los datos, se puede utilizar la función de torch_geometric.data.Data, la cual guardará los datos, las clases, y la información de adyacencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfe896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = geo_torch.data.Data(x=x, y=y, edge_index=edge_index)\n",
    "data.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2154ce",
   "metadata": {},
   "source": [
    "También podemos obtener una gráfica en formato networkx a partir de la función to_networkx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f11d5cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = geo_torch.utils.to_networkx(data, to_undirected=True)\n",
    "nx.draw_networkx(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12586f",
   "metadata": {},
   "source": [
    "## Creación de capas\n",
    "\n",
    "Para crear capas de redes de gráficas, pytroch geometric nos permite definir el procesamiento de estas capas de manera sencilla. Para esto se ocupa <b>torch_geometric.nn.MessagePassing</b>, crearemos entonces una capa de tipo Message Passing que necesita especificar lo siguiente: \n",
    "\n",
    "* La función de agregación, esto se hace después del __init__ de la siguiente forma:\n",
    "```python\n",
    "  super().__init__(aggr='Método_de_agregación')\n",
    "``` \n",
    "Se pueden tomar diferentes métodos de agregación: 1) 'add' - suma; 2) 'mean' - meadia; y 3) 'max' - máximo\n",
    "* Indicar las capas que se van a usar, ya sean de pytorch o pytorch_geometric.\n",
    "* En el forward se indicará el preprocesamiento de los datos y se obtendrá la salida. En el forward mandaremos llamar la función de message por medio de:\n",
    "```python\n",
    "    self.propagate(x=x, edge_index=edge_index)\n",
    "```\n",
    "propagate refiere a la función de la capa $F(x, X_{\\mathcal{N}_x})$, que propaga el mensaje en base a la adyacencia de la gráfica. Se puede agregar un factor de normalización norm=norm si la función de difusión recibe algún tipo de normalización.\n",
    "* La función message se encarga de propagar el mensaje, en este caso, debemos indicar la función de difusión. El mesanje se propagará según la función de agregación que hemos indicado con anterioridad.\n",
    "\n",
    "En la capa de abajo indicamos que queremos agregación de suma en __init__, forward aplicamos una transformación lineal a los datos y calculamos una normalización $norm = \\frac{1}{deg(x_i) deg(x_j)}$, entonces enviamos $x$ y la normalización para que se propaguen. La propagación final, considerando la agregación y demás será de la forma:\n",
    "\n",
    "$$h_i = \\sum_{j \\in \\mathcal{N}_i} \\frac{1}{deg(i)deg(j)} \\psi(x_j) + b$$\n",
    "\n",
    "donde $\\psi(x)$ es una capa lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2fefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv(geo_nn.MessagePassing):\n",
    "    def __init__(self, in_channels=1, out_channels=2):\n",
    "        super().__init__(aggr='add') #La agregación será por suma\n",
    "        #Capa lineal\n",
    "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reinicia los parámetros de la red\"\"\"\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #Añade lazos a la adyacencia para que un nodo sea vecino siempre de sí mismo\n",
    "        edge_index, _ = geo_torch.utils.add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        #Transformación lineal sobre x\n",
    "        x = self.lin(x)\n",
    "\n",
    "        #Computar normalización, raíz cuadrada de grados\n",
    "        row, col = edge_index\n",
    "        deg = geo_torch.utils.degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        #Hacer la difusión de los mensajes\n",
    "        #propagate hace referencia a la función message de abajo\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        #Aplicar el vector del bias después de la difusión\n",
    "        out += self.bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        \"\"\"Determina la difusión del mensaje\"\"\"\n",
    "        #Propagación del mensaje por método aggr\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60337c70",
   "metadata": {},
   "source": [
    "Una vez definida nuestra capa gráfica, podemos definir nuestro modelo de red neuronal, ya sea por medio de un Módulo o usando el método $torch_geometric.nn.Sequential$, que funciona de forma similar a Sequential en torch, pero indicamos los valores que entran (x, y la adyacencia) y como trabajan las capas gráficas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00751895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación del modelo con Sequential\n",
    "model = geo_nn.Sequential('x, edge_index', [(GCNConv(data.num_node_features, 64), 'x,edge_index->x'),\n",
    "                                           nn.ReLU(inplace=True), nn.Linear(64, 2), nn.Softmax(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb13bc",
   "metadata": {},
   "source": [
    "Entrenamos nuestro modelo de forma similar que en torch, sólo notamos que el modelo toma como inputs al vector de entrada y a su adyacencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = risk(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069796cc",
   "metadata": {},
   "source": [
    "Podemos entonces ya usar nuestra red de gráfica con los pesos óptimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a3e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(data.x, data.edge_index).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac5551",
   "metadata": {},
   "source": [
    "## Ejemplo: Sparse AutoEncoder con redes gráficas\n",
    "\n",
    "Para hacer un ejemplo más complejo, podemos definir una especie de sparse autoencoder. En este caso tomaremos imagenes que tengan un sólo canal, y los codificaremos a imagenes con 3 canales. Tomamos el dataset MNIST donde los digitos cuentan con sólo un canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad3e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.array([x_i.reshape(8,8) for x_i in load_digits().data])\n",
    "\n",
    "def plot_images(images, num=4):\n",
    "    \"\"\"Visualización de imagenes\"\"\"\n",
    "    _, axes = plt.subplots(nrows=1, ncols=num, figsize=(10, 3))\n",
    "    for ax, image in zip(axes, images):\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(image)\n",
    "        \n",
    "plot_images(data, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f86a3",
   "metadata": {},
   "source": [
    "Definimos los ejemplos. En este caso, tendremos que codificar los datos en imágenes de 3 canales, después decodificarlo para obtener una reconstrucción de la imagen original. La imagen deseada estará entonces en el medio de la red. La entrada y la salida serán los mismos, definiremos una adyacencia basada en la estructura de grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b3c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada\n",
    "x = torch.Tensor([x_i.reshape(64,1) for x_i in data])\n",
    "#Salida\n",
    "y = torch.Tensor([x_i.reshape(64) for x_i in data])\n",
    "#Adyacencia grid\n",
    "edge_index,_ = geo_torch.utils.grid(8, 8, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a60b5",
   "metadata": {},
   "source": [
    "Usaremos las capas de pytorch_geometric que ya vienen pre-definidas. Algunas de estas capas pueden encontrarse en: https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html\n",
    "Definiremos un encoder que tomará las imagenes con 1 canal y las llevará hacia 3 canales. El decoder tomará estos 3 canales y buscará reconstruir las imágenes originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b5c83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder = geo_nn.Sequential('x, edge_index', [(geo_nn.GCNConv(1, 2), 'x,edge_index->x'),nn.ReLU(),\n",
    "#                                              (geo_nn.GCNConv(2, 3), 'x,edge_index->x'), nn.Sigmoid()])\n",
    "#decoder = geo_nn.Sequential('x, edge_index', [(geo_nn.GCNConv(3, 2), 'x,edge_index->x'), nn.ReLU(),\n",
    "#                                              (geo_nn.GCNConv(2, 1), 'x,edge_index->x'), nn.ReLU()])\n",
    "\n",
    "#encoder = geo_nn.Sequential('x, edge_index', [(geo_nn.FeaStConv(1, 2), 'x,edge_index->x'),nn.ReLU(),\n",
    "#                                              (geo_nn.FeaStConv(2, 3), 'x,edge_index->x'), nn.Sigmoid()])\n",
    "#decoder = geo_nn.Sequential('x, edge_index', [(geo_nn.FeaStConv(3, 2), 'x,edge_index->x'), nn.ReLU(),\n",
    "#                                              (geo_nn.FeaStConv(2, 1), 'x,edge_index->x'), nn.ReLU()])\n",
    "\n",
    "encoder = geo_nn.Sequential('x, edge_index', [(geo_nn.ARMAConv(1, 3), 'x,edge_index->x'), nn.Sigmoid()])\n",
    "decoder = geo_nn.Sequential('x, edge_index', [(geo_nn.FeaStConv(3, 1), 'x,edge_index->x'), nn.ReLU()])\n",
    "\n",
    "encoder.load_state_dict(torch.load('MNISTArma.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325c9c2",
   "metadata": {},
   "source": [
    "Nuestro error será el error cuadrático medio, pues buscaremos que la imagen reconstruida sea lo más similar a la imagen de entrada:\n",
    "\n",
    "$$R(\\theta) = \\frac{1}{2}\\sum_x||x-\\hat{x}||^2$$\n",
    "\n",
    "Donde $\\hat{x}$ es la salida del decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ab75cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:27<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "risk = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    for x_i,y_i in zip(x,y):\n",
    "        h = encoder(x_i, edge_index)\n",
    "        out = decoder(h, edge_index)\n",
    "        optimizer.zero_grad()\n",
    "        y_i = y_i.reshape(64)\n",
    "        loss = risk(out, y_i)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "96f3e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'MNISTArma100.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bcc5b7",
   "metadata": {},
   "source": [
    "Podemos entonces ver cuál es el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e57817f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x_i):\n",
    "    edge_index,_ = geo_torch.utils.grid(8, 8, dtype=torch.long)\n",
    "    h = encoder(x_i, edge_index).detach().numpy()\n",
    "    h = h.reshape(8,8,3)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90de077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = [encode(x_i) for x_i in x[:10]]\n",
    "plot_images(result, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2d157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
