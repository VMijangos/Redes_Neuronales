{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEYMMaqM1hsv"
   },
   "source": [
    "## Red convolucional Tensorflow\n",
    "- En este notebook se definen y regularizan arquitecturas de redes convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NcOcED7h0fE7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWJ2wwp8uGXk"
   },
   "source": [
    "## 1.- Pipeline\n",
    "- El dataset cifar10 consiste de imágenes de resolución $32 \\times 32$. Al ser imágenes RGB se tienen 3 canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-x5HOcPgwrz",
    "outputId": "a517b1d0-ff4d-409a-ab29-6361987c204d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Convert y_train and y_test to one hot \n",
    "y_train = tf.keras.utils.to_categorical(\n",
    "    y_train, num_classes=num_classes, dtype='float32'\n",
    ")\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(\n",
    "    y_test, num_classes=num_classes, dtype='float32'\n",
    ")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OoFP409EhUTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, :])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0mtF2w7ni6f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0jqHzzG8kp8L"
   },
   "outputs": [],
   "source": [
    "ds_len = len(x_train)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TBuQIJhUicTc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 32, 32, 3]), TensorShape([64, 10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "y_test = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(len(train_ds)).batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.zip((x_test, y_test))\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "test_batch = next(iter(train_ds))\n",
    "test_batch[0].shape, test_batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlNrRrpp3EBn"
   },
   "source": [
    "## 2.- Capas\n",
    "- Definir una clase Conv2D(tf.keras.layers.Layer) y su método build() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32, 32, 5), dtype=float32, numpy=\n",
       "array([[[[-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         ...,\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-0.834822  ,  0.827458  , -0.08334106, -0.8090108 ,\n",
       "           0.42283142]],\n",
       "\n",
       "        [[-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         ...,\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-0.834822  ,  0.827458  , -0.08334106, -0.8090108 ,\n",
       "           0.42283142]],\n",
       "\n",
       "        [[-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         ...,\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-0.834822  ,  0.827458  , -0.08334106, -0.8090108 ,\n",
       "           0.42283142]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         ...,\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-0.834822  ,  0.827458  , -0.08334106, -0.8090108 ,\n",
       "           0.42283142]],\n",
       "\n",
       "        [[-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         ...,\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-1.5551076 ,  0.48654872,  0.05096656, -0.53206563,\n",
       "           0.16064602],\n",
       "         [-0.834822  ,  0.827458  , -0.08334106, -0.8090108 ,\n",
       "           0.42283142]],\n",
       "\n",
       "        [[-0.6934795 ,  0.60735977, -0.14366835,  0.29906654,\n",
       "           0.01600015],\n",
       "         [-0.6934795 ,  0.60735977, -0.14366835,  0.29906654,\n",
       "           0.01600015],\n",
       "         [-0.6934795 ,  0.60735977, -0.14366835,  0.29906654,\n",
       "           0.01600015],\n",
       "         ...,\n",
       "         [-0.6934795 ,  0.60735977, -0.14366835,  0.29906654,\n",
       "           0.01600015],\n",
       "         [-0.6934795 ,  0.60735977, -0.14366835,  0.29906654,\n",
       "           0.01600015],\n",
       "         [-0.38787106,  0.11207741, -0.4268023 ,  0.03085153,\n",
       "          -0.09902978]]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Conv2D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, \n",
    "                 strides=1, padding='VALID'):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[self.kernel_size, \n",
    "                                             self.kernel_size,\n",
    "                                             input_shape[-1],\n",
    "                                             self.filters])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.conv2d(inputs, self.kernel, \n",
    "                         strides=[1, self.strides, self.strides, 1],\n",
    "                         padding=self.padding)\n",
    "        return x\n",
    "\n",
    "\n",
    "layer = Conv2D(5, 2, padding='SAME')\n",
    "layer(tf.ones([1, 32, 32, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prueba capa de convoluciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ERlATpwHknEV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 32, 32, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_layer = Conv2D(\n",
    "    filters=5,\n",
    "    kernel_size=3,\n",
    "    strides = 1,\n",
    "    padding='SAME'\n",
    "    )\n",
    "\n",
    "test_output = test_layer(test_batch[0])\n",
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uYrwTccektFB"
   },
   "outputs": [],
   "source": [
    "test_layer2 = Conv2D(\n",
    "    filters=10,\n",
    "    kernel_size=3,\n",
    "    strides = 2,\n",
    "    padding='VALID'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nsaf8_QdnDiZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 15, 15, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output2 = test_layer2(test_output)\n",
    "test_output2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9HdjD4AZoXXb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 2250])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Flatten()(test_output2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4KW2TiE73UD8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definir una clase Linear(tf.keras.layers.Layer) y su método build() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U85l1meq2om8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.       , 0.       , 0.       , 0.       , 0.       , 1.9876688,\n",
       "        0.       , 0.       , 1.0542314, 3.166893 ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Linear(layers.Layer):\n",
    "    def __init__(self, num_outputs, activation=None):\n",
    "        super(Linear, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\",\n",
    "                                      shape=[int(input_shape[-1]), \n",
    "                                             self.num_outputs])\n",
    "        self.bias = self.add_weight(\"bias\",\n",
    "                                    shape=[1, self.num_outputs])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.matmul(inputs, self.kernel) + self.bias\n",
    "\n",
    "        if self.activation == 'relu':\n",
    "            x = tf.nn.relu(x)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            x = tf.math.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "layer = Linear(10, 'relu')\n",
    "layer(tf.ones([1, 784]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Entrenamientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pwlOqleiuY6J"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfQUTJ0zFR36"
   },
   "source": [
    "- Una sola capa convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 1ms/step - loss: 2.0411 - val_loss: 1.9225\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8855 - val_loss: 1.8555\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8378 - val_loss: 1.8195\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.8100 - val_loss: 1.8017\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7931 - val_loss: 1.7864\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7803 - val_loss: 1.7788\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7699 - val_loss: 1.7712\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7609 - val_loss: 1.7623\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7558 - val_loss: 1.7583\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 1.7488 - val_loss: 1.7551\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Conv2D(filters=10, kernel_size=3,\n",
    "           strides = 2, padding='VALID'),\n",
    "    layers.Flatten(),\n",
    "    Linear(10),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model.compile(loss=loss_fn,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=test_ds,\n",
    "  epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6LoX92bs0X0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 10)        270       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2250)              0         \n",
      "                                                                 \n",
      " linear_1 (Linear)           (None, 10)                22510     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,780\n",
      "Trainable params: 22,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agregando más capas convolucionales, activaciones y normalizando por lotes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r3BEdaufu-BB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.6577 - accuracy: 0.4091 - val_loss: 1.4377 - val_accuracy: 0.4848\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 1.3363 - accuracy: 0.5251 - val_loss: 1.3165 - val_accuracy: 0.5293\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 1.2065 - accuracy: 0.5727 - val_loss: 1.2358 - val_accuracy: 0.5601\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.1170 - accuracy: 0.6101 - val_loss: 1.1969 - val_accuracy: 0.5747\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 1.0454 - accuracy: 0.6379 - val_loss: 1.1663 - val_accuracy: 0.5879\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.9820 - accuracy: 0.6619 - val_loss: 1.1433 - val_accuracy: 0.5925\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.9293 - accuracy: 0.6803 - val_loss: 1.1378 - val_accuracy: 0.5999\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.8779 - accuracy: 0.7006 - val_loss: 1.1092 - val_accuracy: 0.6096\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.8315 - accuracy: 0.7192 - val_loss: 1.1063 - val_accuracy: 0.6101\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.7873 - accuracy: 0.7343 - val_loss: 1.1106 - val_accuracy: 0.6105\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Conv2D(filters=16, kernel_size=3,\n",
    "                  strides = 2, padding='VALID'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    Conv2D(filters=32, kernel_size=3,\n",
    "                  strides=2, padding='VALID'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(),\n",
    "    Linear(256, activation='relu'),\n",
    "    Linear(10),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model.compile(loss=loss_fn,\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=test_ds,\n",
    "  epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 15, 15, 16)        432       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 15, 15, 16)       64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 32)          4608      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " linear_2 (Linear)           (None, 256)               401664    \n",
      "                                                                 \n",
      " linear_3 (Linear)           (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,466\n",
      "Trainable params: 409,370\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularizando con dropout para evitar sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aT3f2FFRzctw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.8431 - accuracy: 0.3368 - val_loss: 1.5888 - val_accuracy: 0.4308\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.5630 - accuracy: 0.4388 - val_loss: 1.4211 - val_accuracy: 0.4893\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.4500 - accuracy: 0.4821 - val_loss: 1.3406 - val_accuracy: 0.5210\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.3594 - accuracy: 0.5156 - val_loss: 1.2750 - val_accuracy: 0.5486\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.2908 - accuracy: 0.5379 - val_loss: 1.2300 - val_accuracy: 0.5615\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.2397 - accuracy: 0.5616 - val_loss: 1.2051 - val_accuracy: 0.5700\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.1970 - accuracy: 0.5742 - val_loss: 1.2198 - val_accuracy: 0.5613\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.1555 - accuracy: 0.5904 - val_loss: 1.1322 - val_accuracy: 0.5998\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.1218 - accuracy: 0.6025 - val_loss: 1.1086 - val_accuracy: 0.6061\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 1.0887 - accuracy: 0.6146 - val_loss: 1.1046 - val_accuracy: 0.6097\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Conv2D(filters=16, kernel_size=3,\n",
    "                  strides = 2, padding='VALID'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.ReLU(),\n",
    "    Conv2D(filters=32, kernel_size=3,\n",
    "                  strides=2, padding='VALID'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.ReLU(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    Linear(256, activation='relu'),\n",
    "    Linear(10),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model.compile(loss=loss_fn,\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=test_ds,\n",
    "  epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ykgqXtEt0HAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 16)        432       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 15, 15, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 15, 15, 16)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 32)          4608      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 7, 7, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " linear_4 (Linear)           (None, 256)               401664    \n",
      "                                                                 \n",
      " linear_5 (Linear)           (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409,466\n",
      "Trainable params: 409,370\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhMX-AXmezn-"
   },
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67j85p3fDxbk"
   },
   "source": [
    "- Modificar la arquitectura para mejorar los resultados de evaluación en el conjunto de prueba\n",
    "- Mejorar el entrenamiento"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
