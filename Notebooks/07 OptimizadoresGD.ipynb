{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de optimizción basados en gradiente\n",
    "\n",
    "El gradiente descendiente es el método estándar para realizar optimización de los pesos en una red neuronal. Pero existen diferentes formas de implementar esta optimización, como por ejemplo: Sotchastic Gradient Descent (SGD), Batch Gradient Descent o Mini-batch Gradient Descent. \n",
    "\n",
    "Una parte importante del método de gradiente descendiente es la elección de rango de aprendizaje. Existen métodos que buscan estimar un rango de aprendizaje que pueda permitir una convergencia de los pesos de la red adecuada. Aquí exploramos dos de estos métodos: 1) Adagrad y 2) Adam. Además comparamos con un grdiente descendiente stocástico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento\n",
    "\n",
    "elegimos una tarea de clasificiación binaria simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>¿es animal?</th>\n",
       "      <th>¿es mamífero?</th>\n",
       "      <th>¿es felino?</th>\n",
       "      <th>¿es doméstico?</th>\n",
       "      <th>¿tiene dos orejas?</th>\n",
       "      <th>¿es negro?</th>\n",
       "      <th>¿tiene cuatro patas?</th>\n",
       "      <th>¿es gato?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ¿es animal?   ¿es mamífero?   ¿es felino?   ¿es doméstico?  \\\n",
       "0             1               1             1                1   \n",
       "1             0               0             0                1   \n",
       "2             1               0             1                0   \n",
       "3             1               0             0                0   \n",
       "4             1               0             1                0   \n",
       "5             1               1             1                1   \n",
       "6             1               0             0                1   \n",
       "7             1               1             1                1   \n",
       "8             1               0             0                0   \n",
       "9             0               0             0                0   \n",
       "10            1               0             1                0   \n",
       "11            1               0             1                0   \n",
       "12            1               1             1                1   \n",
       "13            1               1             1                1   \n",
       "14            0               0             0                0   \n",
       "15            1               0             0                0   \n",
       "16            1               0             0                0   \n",
       "17            0               0             0                0   \n",
       "18            1               1             1                1   \n",
       "19            1               1             1                1   \n",
       "20            1               1             1                1   \n",
       "21            1               1             1                1   \n",
       "22            1               1             1                1   \n",
       "23            1               0             0                0   \n",
       "\n",
       "     ¿tiene dos orejas?   ¿es negro?   ¿tiene cuatro patas?   ¿es gato?  \n",
       "0                     1            1                      1           1  \n",
       "1                     0            1                      0           0  \n",
       "2                     0            1                      1           0  \n",
       "3                     1            0                      1           0  \n",
       "4                     1            0                      1           0  \n",
       "5                     0            0                      0           1  \n",
       "6                     1            1                      0           0  \n",
       "7                     0            0                      1           1  \n",
       "8                     0            0                      0           0  \n",
       "9                     0            0                      0           0  \n",
       "10                    1            1                      1           0  \n",
       "11                    1            0                      1           0  \n",
       "12                    1            0                      1           1  \n",
       "13                    1            0                      0           1  \n",
       "14                    0            1                      1           0  \n",
       "15                    1            1                      1           0  \n",
       "16                    0            1                      0           0  \n",
       "17                    0            0                      0           0  \n",
       "18                    1            0                      0           1  \n",
       "19                    1            0                      1           1  \n",
       "20                    0            0                      0           1  \n",
       "21                    1            1                      0           1  \n",
       "22                    1            1                      1           1  \n",
       "23                    1            1                      1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Abrir los datos\n",
    "data = pd.read_csv('cat_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de vectores de entrenamiento: 24, con dimensión: 7\n"
     ]
    }
   ],
   "source": [
    "#Convertir los datos a numpy\n",
    "npData = data.to_numpy()\n",
    "#Ejemplos\n",
    "X = npData[:,:-1]\n",
    "#Clases de los ejemplos\n",
    "Y = npData[:,-1]\n",
    "\n",
    "#Tamaño de los datos\n",
    "#Unidades de entrada\n",
    "N,d = X.shape\n",
    "\n",
    "print('Número de vectores de entrenamiento: {}, con dimensión: {}'.format(N,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos en dos dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reducción de dimensionalidad\n",
    "X_plot = PCA(2).fit_transform(X)\n",
    "#Visualización\n",
    "plt.scatter(X_plot[:,0],X_plot[:,0], c=Y)\n",
    "plt.title('Ploteo de datos de entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preparados los datos de entrenamiento, procedemos a estimar los pesos de la red; para esto, utilizamos en primer lugrar SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD\n",
    "\n",
    "En el SGD se tiene que:\n",
    "\n",
    "* Se actualizan los pesos cada vez que se observa un ejemplo. \n",
    "* El rango de aprendizaje es un hiperparámetro fijo, esto es, no varía durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en iteración 1: 10\n",
      "Error en iteración 2: 2\n",
      "Error en iteración 3: 2\n",
      "Error en iteración 4: 6\n",
      "Error en iteración 5: 0\n",
      "CPU times: user 9.96 ms, sys: 4.99 ms, total: 15 ms\n",
      "Wall time: 11.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Inicializar pesos\n",
    "np.random.seed(0)\n",
    "h_dim = 3\n",
    "W1 = np.random.rand(h_dim,d)/np.sqrt(d)\n",
    "b1 = np.ones(h_dim)\n",
    "W2 = np.random.rand(2,h_dim)/np.sqrt(h_dim)\n",
    "b2 = np.ones(2)\n",
    "\n",
    "#Hiperparámetros\n",
    "its = 1000\n",
    "eta = 1\n",
    "\n",
    "t = 0\n",
    "stop = False\n",
    "while stop == False:\n",
    "    error = 0\n",
    "    for x,y in zip(X,Y):\n",
    "        #FORWARD\n",
    "        a1 = np.dot(W1,x)+b1\n",
    "        h = np.tanh(a1)\n",
    "        a2 = np.dot(W2,h)+b2\n",
    "        exp = np.exp(a2)\n",
    "        f = exp/exp.sum(0)\n",
    "        \n",
    "        #BACKWARD\n",
    "        d_out = exp/exp.sum(0)\n",
    "        d_out[y] -= 1\n",
    "        \n",
    "        d_h = (1-h**2)*np.dot(W2.T,d_out)        \n",
    "\n",
    "        DW2 = np.outer(d_out,h)\n",
    "        Db2 = d_out\n",
    "        \n",
    "        DW1 = np.outer(d_h,x)\n",
    "        Db1 = d_h\n",
    "        \n",
    "        #Actualización de pesos\n",
    "        #El rango de aprendizaje es fijo\n",
    "        W2 -= eta*DW2\n",
    "        b2 -= eta*Db2\n",
    "        W1 -= eta*DW1\n",
    "        b1 -= eta*Db1\n",
    "        \n",
    "        #Error cuadrático\n",
    "        error += (np.argmax(f)-y)**2\n",
    "        \n",
    "    t += 1\n",
    "    print('Error en iteración {}: {}'.format(t,error))\n",
    "    #Condición de finalización\n",
    "    if error == 0 or t == its:\n",
    "        stop = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir una función forward para observar el resultado de la red con los pesos aprendidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def forward(X):\n",
    "    a1 = np.dot(X,W1.T)+b1\n",
    "    h = np.tanh(a1)\n",
    "    a2 = np.dot(h,W2.T)+b2\n",
    "    exp = np.exp(a2)\n",
    "    f = exp/exp.sum(1, keepdims=True)\n",
    "    \n",
    "    return f\n",
    "\n",
    "print(classification_report(np.argmax(forward(X), axis=1),Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAGRAD\n",
    "\n",
    "El método de Adagrad se basa en el SGD, pero aquí el rango de aprendizaje varía, y las actualizaciones se realizan según la regla:\n",
    "\n",
    "$$\\theta_i \\leftarrow \\theta_i - \\frac{\\eta}{\\sqrt{\\mu}+\\epsilon} \\nabla_{\\theta_i} R(\\theta)$$\n",
    "\n",
    "Donde $\\mu$ es un parámetro que varía según la siguiente regla:\n",
    "\n",
    "$$\\mu \\leftarrow \\mu + [\\nabla_{\\theta_i} R(\\theta)]^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en iteración 1: 10\n",
      "Error en iteración 2: 0\n",
      "CPU times: user 24.9 ms, sys: 0 ns, total: 24.9 ms\n",
      "Wall time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Inicializar pesos\n",
    "np.random.seed(0)\n",
    "h_dim = 3\n",
    "W1 = np.random.rand(h_dim,d)/np.sqrt(d)\n",
    "b1 = np.ones(h_dim)\n",
    "W2 = np.random.rand(2,h_dim)/np.sqrt(h_dim)\n",
    "b2 = np.ones(2)\n",
    "\n",
    "#Hiperparámetros\n",
    "its = 1000\n",
    "\n",
    "#Rango de aprendizahe inicial\n",
    "eta = 1\n",
    "#Epsilon\n",
    "eps = 1e-8\n",
    "#Inicialización del parámetro mu\n",
    "#Se utiliza uno para cada matriz de pesos\n",
    "mu1 = 0\n",
    "mub1 = 0\n",
    "mu2 = 0\n",
    "mub2 = 0\n",
    "\n",
    "t = 0\n",
    "stop = False\n",
    "while stop == False:\n",
    "    error = 0\n",
    "    for x,y in zip(X,Y):\n",
    "        #FORWARD\n",
    "        a1 = np.dot(W1,x)+b1\n",
    "        h = np.tanh(a1)\n",
    "        a2 = np.dot(W2,h)+b2\n",
    "        exp = np.exp(a2)\n",
    "        f = exp/exp.sum(0)\n",
    "        \n",
    "        #BACKWARD\n",
    "        d_out = exp/exp.sum(0)\n",
    "        d_out[y] -= 1\n",
    "        d_h = (1-h**2)*np.dot(W2.T,d_out)        \n",
    "\n",
    "        #Derivadas\n",
    "        DW2 = np.outer(d_out,h)\n",
    "        Db2 = d_out\n",
    "        DW1 = np.outer(d_h,x)\n",
    "        Db1 = d_h\n",
    "        \n",
    "        #ADAGRAD\n",
    "        #Actualizació de mu\n",
    "        mu1 += DW1**2\n",
    "        mub1 += Db1**2\n",
    "        mu2 += DW2**2\n",
    "        mub2 += Db2**2\n",
    "        \n",
    "        #Cada matriz de pesos se actualiza por Adagrad\n",
    "        W2 -= (eta/(np.sqrt(mu2)+eps))*DW2\n",
    "        b2 -= (eta/(np.sqrt(mub2)+eps))*Db2\n",
    "        W1 -= (eta/(np.sqrt(mu1)+eps))*DW1\n",
    "        b1 -= (eta/(np.sqrt(mub1)+eps))*Db1\n",
    "        \n",
    "        #Error cuadrático\n",
    "        error += (np.argmax(f)-y)**2\n",
    "        \n",
    "    t += 1\n",
    "    print('Error en iteración {}: {}'.format(t,error))\n",
    "    #Condición de paro\n",
    "    if error == 0 or t == its:\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def forward(X):\n",
    "    a1 = np.dot(X,W1.T)+b1\n",
    "    h = np.tanh(a1)\n",
    "    a2 = np.dot(h,W2.T)+b2\n",
    "    exp = np.exp(a2)\n",
    "    f = exp/exp.sum(1, keepdims=True)\n",
    "    \n",
    "    return f\n",
    "\n",
    "print(classification_report(np.argmax(forward(X), axis=1),Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM\n",
    "\n",
    "Es un método basado en SGD, pero donde el rango de aprendizaje y los valores de cambio varían, siendo que la actualización de los pesos de la red se actualizan por medio de la regla:\n",
    "\n",
    "$$\\theta_i \\leftarrow \\theta_i - \\frac{\\eta}{\\sqrt{\\hat{\\nu}} + \\epsilon} \\hat{m}$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "$$\\hat{m} = \\frac{m}{1-\\beta_1}$$\n",
    "\n",
    "y:\n",
    "\n",
    "$$\\hat{\\nu} = \\frac{\\nu}{1-\\beta_2}$$\n",
    "\n",
    "Tal que $m$ es un parámetro que se actualiza como:\n",
    "\n",
    "$$m \\leftarrow \\beta_1 m + (1-\\beta_1) \\nabla_\\theta R(\\theta)$$\n",
    "\n",
    "Mientras que $\\nu$ es actualizado como:\n",
    "\n",
    "$$\\nu \\leftarrow \\beta_2 \\nu + (1-\\beta_2) [\\nabla_\\theta R(\\theta)]^2$$\n",
    "\n",
    "Aquí, $\\beta_1, \\beta_2\\in [0,1]$ son dos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error en iteración 1: 6\n",
      "Error en iteración 2: 2\n",
      "Error en iteración 3: 0\n",
      "CPU times: user 18.4 ms, sys: 0 ns, total: 18.4 ms\n",
      "Wall time: 14.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Inicializar pesos\n",
    "np.random.seed(0)\n",
    "h_dim = 3\n",
    "W1 = np.random.rand(h_dim,d)/np.sqrt(d)\n",
    "b1 = np.ones(h_dim)\n",
    "W2 = np.random.rand(2,h_dim)/np.sqrt(h_dim)\n",
    "b2 = np.ones(2)\n",
    "\n",
    "#Hiperparámetros\n",
    "#Núm de iteraciones\n",
    "its = 1000\n",
    "\n",
    "#Para ADAM\n",
    "#Rango de aprendizaje inicial\n",
    "eta = 1\n",
    "#Epsilón\n",
    "eps = 1e-8\n",
    "#hiperparámetros beta1 y beta2\n",
    "beta1 = 0.0009\n",
    "beta2 = 0.0009\n",
    "#Inicialización de m y nu\n",
    "#Se tiene uno por cada matriz de pesos\n",
    "m1 = 0\n",
    "mb1 = 0\n",
    "m2 = 0\n",
    "mb2 = 0\n",
    "v1 = 0\n",
    "vb1 = 0\n",
    "v2 = 0\n",
    "vb2 = 0\n",
    "\n",
    "t = 0\n",
    "stop = False\n",
    "while stop == False:\n",
    "    error = 0\n",
    "    for x,y in zip(X,Y):\n",
    "        #FORWARD\n",
    "        a1 = np.dot(W1,x)+b1\n",
    "        h = np.tanh(a1)\n",
    "        a2 = np.dot(W2,h)+b2\n",
    "        exp = np.exp(a2)\n",
    "        f = exp/exp.sum(0)\n",
    "        \n",
    "        #BACKWARD\n",
    "        d_out = exp/exp.sum(0)\n",
    "        d_out[y] -= 1\n",
    "        d_h = (1-h**2)*np.dot(W2.T,d_out)        \n",
    "\n",
    "        #Derivadas\n",
    "        DW2 = np.outer(d_out,h)\n",
    "        Db2 = d_out\n",
    "        DW1 = np.outer(d_h,x)\n",
    "        Db1 = d_h\n",
    "        \n",
    "        #ADAM\n",
    "        #Actualización Primer momento\n",
    "        m1 = beta1*m1 + (1-beta1)*DW1\n",
    "        mb1 = beta1*mb1 + (1-beta1)*Db1\n",
    "        m2 = beta1*m2 + (1-beta1)*DW2\n",
    "        mb2 = beta1*mb2 + (1-beta1)*Db2\n",
    "        #Actualización Segundo momento\n",
    "        v1 = beta2*v1 + (1-beta2)*DW1**2\n",
    "        vb1 = beta2*vb1 + (1-beta2)*Db1**2\n",
    "        v2 = beta2*v2 + (1-beta2)*DW2**2\n",
    "        vb2 = beta2*vb2 + (1-beta2)*Db2**2\n",
    "        \n",
    "        #Ponderación m\n",
    "        m1_p = m1/(1-beta1)\n",
    "        mb1_p = mb1/(1-beta1)\n",
    "        m2_p = m2/(1-beta1)\n",
    "        mb2_p = mb2/(1-beta1)\n",
    "        #Ponderación nu\n",
    "        v1_p = v1/(1-beta2)\n",
    "        vb1_p = vb1/(1-beta2)\n",
    "        v2_p = v2/(1-beta2)\n",
    "        vb2_p = vb2/(1-beta2)\n",
    "        \n",
    "        #Actualización de pesos con ADAM\n",
    "        W2 -= (eta/(np.sqrt(v2_p)+eps))*m2_p\n",
    "        b2 -= (eta/(np.sqrt(vb2_p)+eps))*mb2_p\n",
    "        W1 -= (eta/(np.sqrt(v1_p)+eps))*m1_p\n",
    "        b1 -= (eta/(np.sqrt(vb1_p)+eps))*mb1_p\n",
    "        \n",
    "        #Error cuadrático\n",
    "        error += (np.argmax(f)-y)**2\n",
    "        \n",
    "    t += 1\n",
    "    print('Error en iteración {}: {}'.format(t,error))\n",
    "    #Condición de paro\n",
    "    if error == 0 or t == its:\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def forward(X):\n",
    "    a1 = np.dot(X,W1.T)+b1\n",
    "    h = np.tanh(a1)\n",
    "    a2 = np.dot(h,W2.T)+b2\n",
    "    exp = np.exp(a2)\n",
    "    f = exp/exp.sum(1, keepdims=True)\n",
    "    \n",
    "    return f\n",
    "\n",
    "print(classification_report(np.argmax(forward(X), axis=1),Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
